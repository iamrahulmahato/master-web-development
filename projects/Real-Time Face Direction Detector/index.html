<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Direction Detector</title>
    <style>
        body {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
            background-color: #222;
            color: #fff;
            font-family: Arial, sans-serif;
        }
        video {
            border: 2px solid #4caf50;
            border-radius: 10px;
        }
        h1 {
            margin-top: 10px;
        }
    </style>
</head>
<body>

    <h1>Real-Time Face Direction Detector</h1>
    <video id="video" autoplay playsinline width="640" height="480"></video>
    <h1 id="direction">Loading...</h1>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>

    <script>
        const video = document.getElementById('video');
        const direction = document.getElementById('direction');

        // Load webcam video stream
        async function setupWebcam() {
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
            return new Promise(resolve => {
                video.onloadedmetadata = () => resolve(video);
            });
        }

        // Load face landmark model and start detecting
        async function detectFaceDirection() {
            const model = await faceLandmarksDetection.load(
                faceLandmarksDetection.SupportedPackages.mediapipeFacemesh
            );

            async function detect() {
                const predictions = await model.estimateFaces({ input: video });
                if (predictions.length > 0) {
                    const landmarks = predictions[0].scaledMesh;
                    const nose = landmarks[1];  // Nose landmark
                    const leftEye = landmarks[33];
                    const rightEye = landmarks[263];

                    // Calculate direction based on nose position
                    if (nose[0] < leftEye[0]) direction.textContent = 'Looking Right';
                    else if (nose[0] > rightEye[0]) direction.textContent = 'Looking Left';
                    else direction.textContent = 'Looking Center';
                }
                requestAnimationFrame(detect);
            }
            detect();
        }

        // Initialize webcam and start detection
        setupWebcam().then(() => detectFaceDirection());
    </script>

</body>
</html>
